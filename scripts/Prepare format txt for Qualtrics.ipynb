{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Simple txt to import to Qualtrics. [Link](https://www.qualtrics.com/support/survey-platform/survey-module/survey-tools/import-and-export-surveys/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_messages = pd.read_csv('/home/pcallec/smoking_cessation_messages/results/vC/joined_output_vC_ChatGPT/joined_results_100.csv',\n",
    "                          index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You have the power to live your life without c...</td>\n",
       "      <td>gpt-j-6B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Your success isn’t determined by how much you ...</td>\n",
       "      <td>gpt-j-6B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To stop smoking completely, you need to go thr...</td>\n",
       "      <td>gpt-j-6B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are your interests? What do you like to d...</td>\n",
       "      <td>gpt-j-6B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Talk to your friends, family, and colleagues a...</td>\n",
       "      <td>gpt-j-6B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Message     model\n",
       "0  You have the power to live your life without c...  gpt-j-6B\n",
       "1  Your success isn’t determined by how much you ...  gpt-j-6B\n",
       "2  To stop smoking completely, you need to go thr...  gpt-j-6B\n",
       "3  What are your interests? What do you like to d...  gpt-j-6B\n",
       "4  Talk to your friends, family, and colleagues a...  gpt-j-6B"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_models = df_messages[\"model\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gpt-j-6B', 'opt-30b', 'original', 'ChatGPT', 'opt-13b',\n",
       "       'opt-6.7b', 'bloom-7b1'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_directory = \"/home/pcallec/smoking_cessation_messages/results/Qualtrics/messages_for_questionnaires\"\n",
    "\n",
    "n_questionnaires = 14\n",
    "\n",
    "dict_count = defaultdict(int)\n",
    "for i_questionnaire in range(n_questionnaires):\n",
    "    \n",
    "    df_temp = pd.DataFrame()\n",
    "    \n",
    "    # in order to distribute evenly the numbers of messages\n",
    "    # among the questionnaires, we had 8 messages only two times in the 14 questionnaire\n",
    "    # That is a model has: 12*7+2*8 = 100 messages in the 14 questionnaire\n",
    "    \n",
    "    # Quantity of messsage per model in each questionnaire\n",
    "#            0 1 2 3 4 5 6 7 8 9 10 11 12 13\n",
    "    # model1 8 7 7 7 7 7 7 8 7 7  7  7  7  7\n",
    "    # model2 7 8 7 7 7 7 7 7 8 7  7  7  7  7\n",
    "    # model3 7 7 8 7 7 7 7 7 7 8  7  7  7  7\n",
    "    # model4 7 7 7 8 7 7 7 7 7 7  8  7  7  7\n",
    "    # model5 7 7 7 7 8 7 7 7 7 7  7  8  7  7\n",
    "    # model6 7 7 7 7 7 8 7 7 7 7  7  7  8  7\n",
    "    # model7 7 7 7 7 7 7 8 7 7 7  7  7  7  8\n",
    "    \n",
    "    for i_model, model in enumerate(l_models):\n",
    "        old_count = dict_count[model]\n",
    "        if i_questionnaire % 7 == i_model:\n",
    "            dict_count[model]+=8\n",
    "        else:\n",
    "            dict_count[model]+=7\n",
    "    \n",
    "        df_subset = df_messages[ df_messages[\"model\"] == model].iloc[old_count:dict_count[model],:]\n",
    "        df_temp = pd.concat([df_temp, df_subset], ignore_index=True)\n",
    "#     print(i_questionnaire, Counter(df_temp[\"model\"]))\n",
    "\n",
    "    df_temp_shuffled = df_temp.sample(frac = 1, ignore_index=True)\n",
    "    \n",
    "    os.makedirs(path_directory, exist_ok = True)\n",
    "    filename = f\"messages_for_questionnaire_{i_questionnaire+1}.csv\"\n",
    "    path_file = os.path.join(path_directory, filename)\n",
    "    \n",
    "    df_temp_shuffled.to_csv(path_file)\n",
    "#     break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st round of questionnaires\n",
    "First 7 questionnaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_output_directory = \"/home/pcallec/smoking_cessation_messages/results/Qualtrics/questionnaires_code\"\n",
    "path_messages_directory = \"/home/pcallec/smoking_cessation_messages/results/Qualtrics/messages_for_questionnaires\"\n",
    "\n",
    "n_questionnaires = 7\n",
    "\n",
    "os.makedirs(path_output_directory, exist_ok = True)\n",
    "\n",
    "for i_questionnaire in range(n_questionnaires):\n",
    "    str_start_all = \"[[AdvancedFormat]]\\n\\n\"\n",
    "    \n",
    "    filename_messages = f\"messages_for_questionnaire_{i_questionnaire+1}.csv\"\n",
    "    path_messages = os.path.join(path_messages_directory, filename_messages)\n",
    "    \n",
    "    df_messages = pd.read_csv(path_messages, index_col=0)\n",
    "\n",
    "    str_all = str_start_all\n",
    "    \n",
    "    n_messages = df_messages.shape[0]\n",
    "    \n",
    "    str_block_intro = \"[[Block: Message Intro]]\\n\\n\"\n",
    "    str_intro = f\"[[Question:Text]]\\n[[ID:Intro]]\\n\"+ \\\n",
    "                 \"Creation of smoking cessation treatment messages can be time consuming. \"+ \\\n",
    "                 \"We have been working with computer scientists to develop methods that involve\" + \\\n",
    "                 \"using artificial intelligence to create new treatment messages. We would like \" + \\\n",
    "                 \"you to evaluate two sets of 50 messages each. The first set is attached to this \" + \\\n",
    "                 \"Qualtrics survey. Please use TTS standards and your best judgement and follow the \" + \\\n",
    "                 \"directions in the link to evaluate and improve the messages.\\n\\n\"\n",
    "    \n",
    "    str_breakpage = \"[[PageBreak]]\\n\\n\"\n",
    "    \n",
    "    str_all = str_all + str_block_intro + str_intro + str_breakpage\n",
    "    \n",
    "    for i_message in range(n_messages):\n",
    "        str_block_start = f\"[[Block: Message {i_message+1}]]\\n\\n\"\n",
    "        message = df_messages.loc[i_message,\"Message\"]\n",
    "        str_message_1 = f\"[[Question:Text]]\\n[[ID:M{i_message+1}_message_1]]\" + \\\n",
    "                        f\"\\nMessage {i_message+1} out of {n_messages}:<br>\\n\" + \\\n",
    "                        f\"{message}\\n\\n\"\n",
    "        str_question_style = f\"[[Question:MC:SingleAnswer:Horizontal]]\\n[[ID:M{i_message+1}_style]]\\n\"+ \\\n",
    "                              \"Considering both content and style, how well-written is the message?\\n\"+ \\\n",
    "                              \"[[Choices]]\\n1-Poorly Written\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10-Very Well-Written\\n\\n\"\n",
    "\n",
    "        str_question_accuracy = f\"[[Question:MC:SingleAnswer:Horizontal]]\\n[[ID:M{i_message+1}_accuracy]]\\n\"+ \\\n",
    "                              \"How accurate is this message? (Accurate refers to no misinformation and no factual errors)\\n\"+ \\\n",
    "                              \"[[Choices]]\\n1-Not at all\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10-Very Much\\n\\n\"\n",
    "       \n",
    "        str_question_credibility = f\"[[Question:MC:SingleAnswer:Horizontal]]\\n[[ID:M{i_message+1}_credibility]]\\n\"+ \\\n",
    "                              \"How credible does this message seem to you?\\n\"+ \\\n",
    "                              \"[[Choices]]\\n1-Not at all\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10-Very Much\\n\\n\"\n",
    "\n",
    "        str_question_persuasion = f\"[[Question:MC:SingleAnswer:Horizontal]]\\n[[ID:M{i_message+1}_persuasion]]\\n\"+ \\\n",
    "                              \"To what extent do you feel this message can help smokers avoid smoking?\\n\"+\\\n",
    "                              \"[[Choices]]\\n1-Not at all\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10-Very Much\\n\\n\"\n",
    "\n",
    "\n",
    "        str_message_2 = f\"[[Question:Text]]\\n[[ID:M{i_message+1}_message_2]]\" + \\\n",
    "                        f\"\\nMessage {i_message+1} out of {n_messages}:<br>\\n\" + \\\n",
    "                        f\"{message}\\n\\n\"\n",
    "        str_question_revision_choice = f\"[[Question:MC:SingleAnswer:Vertical]]\\n[[ID:M{i_message+1}_revision_option]]\\n\"+\\\n",
    "                                        \"Based on the TTS standards, do you feel this message needs further revision? \"+\\\n",
    "                                        \"If so, please revise it into a high-quality one in the text box.\\n\" +\\\n",
    "                                        \"[[Choices]]\\nNo need to revise, it meets TTS standards already\\n\"+\\\n",
    "                                        \"Yes, it needs further revision. Please revise the message in the text box below.\\n\"\n",
    "        \n",
    "        str_question_revision_text = f\"[[Question:TextEntry]]\\n[[ID:M{i_message+1}_revision]]\\n\"+\\\n",
    "                                      \"Revise here:\\n\\n\"\n",
    "#                               \"[[SingleLine]]\\n\\n\\n\"\n",
    "                \n",
    "        str_question_template = f\"[[Question:TextEntry]]\\n[[ID:M{i_message+1}_timing]]\\n\\n\"\n",
    "        \n",
    "        str_all = str_all + str_block_start + str_message_1 + str_question_style + str_question_accuracy  + \\\n",
    "                  str_question_credibility + str_question_persuasion + str_breakpage + str_message_2 + \\\n",
    "                  str_question_revision_choice + str_question_revision_text + str_question_template\n",
    "    \n",
    "#     print(i_questionnaire)\n",
    "    filename = f\"questionnaire_{i_questionnaire+1}.txt\"\n",
    "    path_file = os.path.join(path_output_directory, filename)\n",
    "    f = open(path_file, \"w\", encoding='utf-8')\n",
    "    f.write(str_all)\n",
    "    f.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd round of messages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next 7 questionnaires. Main difference is in the introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_output_directory = \"/home/pcallec/smoking_cessation_messages/results/Qualtrics/questionnaires_code\"\n",
    "path_messages_directory = \"/home/pcallec/smoking_cessation_messages/results/Qualtrics/messages_for_questionnaires\"\n",
    "\n",
    "n_questionnaires = 14\n",
    "\n",
    "os.makedirs(path_output_directory, exist_ok = True)\n",
    "\n",
    "for i_questionnaire in range(7,n_questionnaires):\n",
    "    str_start_all = \"[[AdvancedFormat]]\\n\\n\"\n",
    "    \n",
    "    filename_messages = f\"messages_for_questionnaire_{i_questionnaire+1}.csv\"\n",
    "    path_messages = os.path.join(path_messages_directory, filename_messages)\n",
    "    \n",
    "    df_messages = pd.read_csv(path_messages, index_col=0)\n",
    "\n",
    "    str_all = str_start_all\n",
    "    \n",
    "    n_messages = df_messages.shape[0]\n",
    "    \n",
    "    str_block_intro = \"[[Block: Message Intro]]\\n\\n\"\n",
    "    str_intro = f\"[[Question:Text]]\\n[[ID:Intro]]\\n\"+ \\\n",
    "                 \"Thank you for providing your feedback on the first set of 50 messages! \"+ \\\n",
    "                 \"We appreciate your effort and contribution to this project. \" + \\\n",
    "                 \"For the rest of the project, we would like you to review another 50 messages following \" + \\\n",
    "                 \"the same procedure. Please use TTS standards and your best judgment and \" + \\\n",
    "                 \"follow the directions in the link to evaluate and improve the messages. \" + \\\n",
    "                 \"Make sure to put the revised messages, instead of your comments in the text box. \" + \\\n",
    "                 \"DO NOT put comments in the revision box. Thank you!\\n\\n\"\n",
    "    \n",
    "    str_breakpage = \"[[PageBreak]]\\n\\n\"\n",
    "    \n",
    "    str_all = str_all + str_block_intro + str_intro + str_breakpage\n",
    "    \n",
    "    for i_message in range(n_messages):\n",
    "        str_block_start = f\"[[Block: Message {i_message+1}]]\\n\\n\"\n",
    "        message = df_messages.loc[i_message,\"Message\"]\n",
    "        str_message_1 = f\"[[Question:Text]]\\n[[ID:M{i_message+1}_message_1]]\" + \\\n",
    "                        f\"\\nMessage {i_message+1} out of {n_messages}:<br>\\n\" + \\\n",
    "                        f\"{message}\\n\\n\"\n",
    "        str_question_style = f\"[[Question:MC:SingleAnswer:Horizontal]]\\n[[ID:M{i_message+1}_style]]\\n\"+ \\\n",
    "                              \"Considering both content and style, how well-written is the message?\\n\"+ \\\n",
    "                              \"[[Choices]]\\n1-Poorly Written\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10-Very Well-Written\\n\\n\"\n",
    "\n",
    "        str_question_accuracy = f\"[[Question:MC:SingleAnswer:Horizontal]]\\n[[ID:M{i_message+1}_accuracy]]\\n\"+ \\\n",
    "                              \"How accurate is this message? (Accurate refers to no misinformation and no factual errors)\\n\"+ \\\n",
    "                              \"[[Choices]]\\n1-Not at all\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10-Very Much\\n\\n\"\n",
    "       \n",
    "        str_question_credibility = f\"[[Question:MC:SingleAnswer:Horizontal]]\\n[[ID:M{i_message+1}_credibility]]\\n\"+ \\\n",
    "                              \"How credible does this message seem to you?\\n\"+ \\\n",
    "                              \"[[Choices]]\\n1-Not at all\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10-Very Much\\n\\n\"\n",
    "\n",
    "        str_question_persuasion = f\"[[Question:MC:SingleAnswer:Horizontal]]\\n[[ID:M{i_message+1}_persuasion]]\\n\"+ \\\n",
    "                              \"To what extent do you feel this message can help smokers avoid smoking?\\n\"+\\\n",
    "                              \"[[Choices]]\\n1-Not at all\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10-Very Much\\n\\n\"\n",
    "\n",
    "\n",
    "        str_message_2 = f\"[[Question:Text]]\\n[[ID:M{i_message+1}_message_2]]\" + \\\n",
    "                        f\"\\nMessage {i_message+1} out of {n_messages}:<br>\\n\" + \\\n",
    "                        f\"{message}\\n\\n\"\n",
    "        str_question_revision_choice = f\"[[Question:MC:SingleAnswer:Vertical]]\\n[[ID:M{i_message+1}_revision_option]]\\n\"+\\\n",
    "                                        \"Based on the TTS standards, do you feel this message needs further revision? \"+\\\n",
    "                                        \"If so, please revise it into a high-quality one in the text box.\\n\" +\\\n",
    "                                        \"[[Choices]]\\nNo need to revise, it meets TTS standards already\\n\"+\\\n",
    "                                        \"Yes, it needs further revision. Please revise the message in the text box below.\\n\"\n",
    "        \n",
    "        str_question_revision_text = f\"[[Question:TextEntry]]\\n[[ID:M{i_message+1}_revision]]\\n\"+\\\n",
    "                                      \"Revise here:\\n\\n\"\n",
    "#                               \"[[SingleLine]]\\n\\n\\n\"\n",
    "                \n",
    "        str_question_template = f\"[[Question:TextEntry]]\\n[[ID:M{i_message+1}_timing]]\\n\\n\"\n",
    "        \n",
    "        str_all = str_all + str_block_start + str_message_1 + str_question_style + str_question_accuracy  + \\\n",
    "                  str_question_credibility + str_question_persuasion + str_breakpage + str_message_2 + \\\n",
    "                  str_question_revision_choice + str_question_revision_text + str_question_template\n",
    "    \n",
    "#     print(i_questionnaire)\n",
    "    filename = f\"questionnaire_{i_questionnaire+1}.txt\"\n",
    "    path_file = os.path.join(path_output_directory, filename)\n",
    "    f = open(path_file, \"w\", encoding='utf-8')\n",
    "    f.write(str_all)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_messages.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu2.6.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
